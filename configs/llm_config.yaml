# Configuração otimizada para diferentes GPUs

# RTX 5090 Ti / A100 (48GB VRAM)
ultra_high_end:
  batch_size: 32
  max_concurrent: 16
  model: "qwen2.5:14b"  # Modelo grande

# RTX 4090 / H100 (24GB VRAM)
high_end:
  batch_size: 16
  max_concurrent: 8
  model: "qwen2.5:14b"  # Modelo grande

# RTX 5080 / 3080 (16GB VRAM)
upper_mid_range:
  batch_size: 12
  max_concurrent: 6
  model: "qwen2.5:7b"

# RTX 4060 / 3060 (12GB VRAM)
mid_range:
  batch_size: 8
  max_concurrent: 4
  model: "qwen2.5:7b"

# GTX 1660 / RTX 2060 (6GB VRAM)
low_end:
  batch_size: 4
  max_concurrent: 2
  model: "qwen2.5:3b"

# CPU only
cpu:
  batch_size: 2
  max_concurrent: 1
  model: "qwen2.5:3b"